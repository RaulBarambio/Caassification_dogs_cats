# -*- coding: utf-8 -*-
"""Clasification_cats_dogs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yssDOu5MYik9LCyF3cJiJQFTNRtGlOmx
"""

# Import
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow
import numpy as np
from tensorflow.keras.callbacks import TensorBoard

#Importamos los datos
data, metadata = tfds.load('cats_vs_dogs', as_supervised = True, with_info = True)

#Vamos a ver los datos
#Tamaño de las imagenes
plt.figure(figsize = (10,10))

#Pixeles
size_img = 80

for i, (imagen, etiqueta) in enumerate(data['train'].take(9)):
  imagen = cv2.resize(imagen.numpy(), (size_img, size_img))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  plt.subplot(3,3,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(imagen, cmap = 'gray')

#Pasar todas a gris y ridimensionar
data_train = []

for i, (imagen, etiqueta) in enumerate(data['train']):
  imagen = cv2.resize(imagen.numpy(), (size_img, size_img))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  imagen = imagen.reshape(size_img, size_img, 1)
  data_train.append([imagen, etiqueta])

#Número de imagenes en el dataset
len(data_train)

#Dividir entre X e Y
X = []
y = []

for imagen, etiqueta in data_train:
  X.append(imagen)
  y.append(etiqueta)

#Normalización de valores
X = np.array(X).astype(float) / 255
y = np.array(y)

print(X.shape) #Imagenes, dimensionxdimension, 1 escala de color
print(y)

"""Modelo Denso"""

#Crear los modelos iniciales
modeloDenso = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(80, 80, 1)),
  tf.keras.layers.Dense(150, activation='relu'), #Capa densa 150 neuronas
  tf.keras.layers.Dense(150, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid') #Usan sigmoid como salida (en lugar de softmax) para mostrar como podria funcionar con dicha funcion de activacion.
])

"""Modelos convolucionaes"""

modeloCNN = tf.keras.models.Sequential([ #Red convolucional
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(80, 80, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

modeloCNN2 = tf.keras.models.Sequential([ #Red convolucional pero con un Dropout
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(80, 80, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Dropout(0.5), #Dropout para evitar sobreajuste
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(250, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

#Compilar modelos. Usar crossentropy binario ya que tenemos solo 2 opciones (perro o gato)
modeloDenso.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

modeloCNN.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

modeloCNN2.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

tensorboardDenso = TensorBoard(log_dir='logs/denso')
#Indicamos division y epocas
modeloDenso.fit(X, y, batch_size=32,validation_split=0.15,epochs=100,callbacks=[tensorboardDenso])

tensorboardCNN = TensorBoard(log_dir='logs/CNN')
#Indicamos division y epocas
modeloCNN.fit(X, y, batch_size=32,validation_split=0.15,epochs=100,callbacks=[tensorboardCNN])

tensorboardCNN2 = TensorBoard(log_dir='logs/CNN2')
#Indicamos division y epocas
modeloCNN2.fit(X, y, batch_size=32,validation_split=0.15,epochs=100,callbacks=[tensorboardCNN2])

# Commented out IPython magic to ensure Python compatibility.
#Cargar la extension de tensorboard de colab
# %load_ext tensorboard
#Ejecutar tensorboard e indicarle que lea la carpeta "logs"
# %tensorboard --logdir logs

"""Generación de imagenes nuevas para poder entrenar el modelo"""

#Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=15,
    zoom_range=[0.7, 1.4],
    horizontal_flip=True,
    vertical_flip=True
)

datagen.fit(X)

plt.figure(figsize=(20,8))

for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):
  for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(imagen[i].reshape(80, 80), cmap="gray")
  break

modeloDenso_MD = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(80, 80, 1)),
  tf.keras.layers.Dense(150, activation='relu'),
  tf.keras.layers.Dense(150, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

modeloCNN_MD = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(80, 80, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

modeloCNN2_MD = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(80, 80, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(250, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

modeloDenso_MD.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

modeloCNN_MD.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

modeloCNN2_MD.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

# Entrenamiento un 85% y el resto a validacion
X_entrenamiento = X[:19700]
X_validacion = X[19700:]

y_entrenamiento = y[:19700]
y_validacion = y[19700:]

#Generamos nuevas imagenes con escalado, zoom...
data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)

tensorboardDenso_MD = TensorBoard(log_dir='logs/denso_MD')

modeloDenso_MD.fit(
    data_gen_entrenamiento,
    epochs=100, batch_size=32,
    validation_data=(X_validacion, y_validacion),
    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),
    validation_steps=int(np.ceil(len(X_validacion) / float(32))),
    callbacks=[tensorboardDenso_MD]
)

tensorboardCNN_MD = TensorBoard(log_dir='logs-new/cnn_MD')

modeloCNN_MD.fit(
    data_gen_entrenamiento,
    epochs=150, batch_size=32,
    validation_data=(X_validacion, y_validacion),
    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),
    validation_steps=int(np.ceil(len(X_validacion) / float(32))),
    callbacks=[tensorboardCNN_MD]
)

tensorboardCNN2_MD = TensorBoard(log_dir='logs/cnn2_MD')

modeloCNN2_MD.fit(
    data_gen_entrenamiento,
    epochs=100, batch_size=32,
    validation_data=(X_validacion, y_validacion),
    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),
    validation_steps=int(np.ceil(len(X_validacion) / float(32))),
    callbacks=[tensorboardCNN2_MD]
)

# Commented out IPython magic to ensure Python compatibility.
#Cargar la extension de tensorboard de colab
# %load_ext tensorboard
#Ejecutar tensorboard e indicarle que lea la carpeta "logs"
# %tensorboard --logdir logs

"""El modelo más corercto sería el cnn2 ya que vemos el acurracy llega al casi 85% y la perdida desciende igual entre entrenamineto y test por lo tanto no hay un sobreajuste"""

